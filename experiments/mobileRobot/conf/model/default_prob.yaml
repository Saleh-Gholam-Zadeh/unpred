wandb:
  log: True
  project_name: 'Probabilistic_pred_per_cpu_'
  #project_name: 'Model_comparison_per_cpu_'
  #project_name: 'visualize_residual'
  #project_name: 'compute_residual'
  #exp_name: 'visualize_left_and_right_side_of_bar_chart'
  exp_name: 'NonStationary_per_flow_Multires'
  #exp_name: 'MLP_plus_per_flow_'

  #exp_name: 'tmp_NST'
  sweep: False
  sweep_id: null

learn:
  seed: 0
  num_class: 70  # every 2% is a bin [0% 140%]
  #load: True
  load: False
  #gpu: '0'
  #epochs: 250
  epochs: 75

  batch_size: 450
  #batch_size: 150
  latent_vis: False
  plot_traj: False
  #latent_vis: True
  #plot_traj: True
  lr: 5e-4
  #lr: 5e-4
  save_model: True
  #loss: 'nll'  /// 'kl_rmse'
  #loss: 'mae'
  #loss: 'mse'
  loss: 'cross_entropy'
  #loss: 'kl_rmse'  # KL + packet_rmse
  #loss: 'kl_cross' kl(dist) + cross_entropy entropy on packets
  features_in: 'all'  # or 'packets'
  #features_out: 'all' # or 'packets'
  #features_in: 'packets'
  features_out: 'packets'

transformer_arch:
#  enc_layer: 4
#  dec_layer: 2
#  n_head: 8
#  d_model: 256
#  dropout: 0.1
  enc_layer: 2
  dec_layer: 1
  n_head: 4
  d_model: 128
  dropout: 0.1

  factor: 3
  seq_len: 49
  p_hidden_layers: 2
  p_hidden_dims: [128 ,128]



np:
  clip_gradients: True
  latent_obs_dim: 30  #orig
  #latent_obs_dim: 60
  agg_dim: 60  #orig
  #agg_dim: 120


set_encoder:
  encoder_hidden_units: [240] #orig
  #encoder_hidden_units: [240 , 120]
  aggregator: 'BA'
  enc_out_norm: 'post'
  variance_act: 'softplus'

ssm_decoder:
  kalman_linear: True
  num_basis: 15
  bandwidth: 3
  enc_net_hidden_units: [ 120 ] #orig
  dec_net_hidden_units: [ 240 ] #orig
#  enc_net_hidden_units: [ 1000, 500 ]
#  dec_net_hidden_units: [ 1000, 500 ]

  trans_net_hidden_units: [ ]
  #control_net_hidden_units: [ 120 ]
  control_net_hidden_units: [ 1 ]
  task_net_hidden_units: [ 120 ]
  process_noise_hidden_units: [ 30 ]
  trans_net_hidden_activation: "Tanh"
  control_net_hidden_activation: 'ReLU'
  process_noise_hidden_activation: 'ReLU'
  task_net_hidden_activation: 'ReLU'
  learn_trans_covar: True
  decoder_conditioning: False
  additive_linear_task: False
  additive_linear_task_factorized: False
  additive_l_linear_task_factorized: False
  additive_nl_task: True
  additive_nl_task_deterministic: False
  nl_diagonal: True
  additive_ll_task: False
  multi_gaussian_l_transform: False
  trans_covar: 0.1
  learn_initial_state_covar: False
  initial_state_covar: 10
  enc_out_norm: 'post'
  clip_gradients: True
  never_invalid: False
  variance_act: 'softplus'
  num_heads: 1

data_reader:
  portion: 0
  imp: 0 # 75% for longer step ahead. for single can be set to 0
  terrain: 'sin2'
  frequency: '500'
  meta_batch_size: 300000   #400000 --> 162Gb RAM
  #meta_batch_size: 150000

  #batch_size: 150
  #batch_size: 64 #context_size
  context_size: 49 #context_size
  pred_len: 1
  #tar_type: 'delta' # Use "delta" argument to predict on the differences as targets. In other cases use "observations".
  tar_type: 'observations'
  #load: null
  load: True
  save: 1
  dim: 111
  standardize: True  #havaset bashe target distribution ro normalize nakoni
  standardize_dist: False
  #flows: ['flow_48'] # a list for per_flow model
  flows: None #---> single model for all flows
  #standardize: False

#  split:
#    - [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,41,42,43,44,45,46,47,48,49]
#    - [30,31,32,33,34,35,36,37,38,39,40]

#  split:
#    - [ 1,3,5,7,9,11,13,15,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,42,43,44,45,46,47,48,49,50 ]
#    - [ 2,4,6,8,10,12,14,16,39,40,41 ]

  split:
    - [ 0,2,4,6,8,10,12,14,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,41,42,43,44,45,46,47,48,49 ]
    - [ 1,3,5,7,9,11,13,15,39,40 ]


  shuffle_split: null
  file_name: 'MobileWindows'
  trajPerTask: 10

submitit:
  folder: './experiments/mujoco_meta/Ant/slurm_output/'
  name: 'jobtrial'
  timeout_min: 10
  mem_gb: 10
  nodes: 1
  cpus_per_task: 3
  gpus_per_node: 1
  tasks_per_node: 1
  slurm_partition: gpu
